# Music-Generation-Model
Transformer-based deep learning model trained on Magenta dataset using Tensorflow and numpy to synthesize classical  and jazz music. Uses novel embedding layer to encode continuous temporal information about music notes to improve model versatility to  handle complex rhythms and time signatures 

Requires maestro dataset, pretty midi, tensorflow. Data used to train the model is found as a zip file, unzip and put in `data/` folder in root directory to use.

Main code is in `musictransformer.ipynb`
